{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy - a tour...\n",
    "\n",
    "### Adrian Price-Whelan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy contains many subpackages, each of which we will have to import separately. There are no real standards for these imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import signal, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy contains many sub-packages with many useful functions and utilities for scientific programming. Other notebooks in this directory contain more in-depth looks at the `optimize`, `integrate`, and `interpolate` sub-packages, but this notebook is supposed to serve as a quick look at some of the functions that I've found to be most useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subpackage contains tools for signal processing. There are tools for doing cross-correlation, filtering, making periodograms, and etc. These two functions, buried in the documentation, come in handy for me all the time: \n",
    "\n",
    "`argrelmax` and `argrelmin`\n",
    "\n",
    "`argrelmax` finds the indices of relative maxima in a given array. For example, let's create a time series with cosine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.linspace(0,5,2048)\n",
    "f = np.cos(2*np.pi*t)\n",
    "idx, = signal.argrelmax(f)\n",
    "\n",
    "plt.plot(t, f, marker=None, color='k', linewidth=2.)\n",
    "\n",
    "for i in idx:\n",
    "    plt.axvline(t[i], color='r')\n",
    "\n",
    "plt.ylim(-1.1,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has many useful applications, but to name one, if you want to quickly estimate the period of a (well-sampled) time series, you can use this to find successive peaks in the array, then just difference the times at neighboring indices. For example, the period for the above time series is 1.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(t[idx[1:]] - t[idx[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`argrelmin` does the same, but for relative minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements many probability distributions. Numpy contains functions for sampling from probability distributions, but scipy.stats contains objects (one per distribution) that let you compute the pdf, logpdf, cdf, and also sample from them (to name a few attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to sample from a 1D Normal (Gaussian) distribution, we could use `np.random.normal`, but if we want to evaluate the probability density at some location, there is no built-in function in numpy. Instead, we could use the `norm` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-3.,5.,100)\n",
    "p = stats.norm.pdf(x, loc=0.4, scale=1.1)\n",
    "plt.plot(x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = stats.norm.cdf(x, loc=0.4, scale=1.1)\n",
    "plt.plot(x, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also utilities for computing moments of distributions of points, e.g., the skewness or kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = stats.lognorm.rvs(0.4, size=1000)\n",
    "plt.hist(xs, bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.skew(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.kurtosis(xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
